{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "The functions used here are listed below:\n",
    "\n",
    "- [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split)\n",
    "- [cross_val_score](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)\n",
    "- [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)\n",
    "\n",
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm, preprocessing, datasets\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In scikit-learn a random split into training and test sets can be quickly computed with the `train_test_split` helper function. `train_size` and `test_size` parameters can be used to specify the sizes of training and test sets. The default is 75% in train and 25% in test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n",
      "(90, 4) (90,)\n",
      "(60, 4) (60,)\n",
      "0.966666666667\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "print(iris.data.shape, iris.target.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, \n",
    "                                                                    test_size=0.4, random_state=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation using `cross_val_score`\n",
    "\n",
    "The simplest way to use cross-validation is to call the `cross_val_score` helper function on the estimator and the dataset. **It can be parallelized using `n_jobs` argument.It preserves the percentage of samples for each class for labeled data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.96666667  1.          0.96666667  0.96666667  1.        ]\n",
      "Accuracy: 0.98 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = cross_val_score(clf, iris.data, iris.target, cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the score computed at each CV iteration is the score method of the estimator. It is possible to change this by using the `scoring` parameter.\n",
    "\n",
    "### Cross Validation using `cross_validate`\n",
    "\n",
    "The `cross_validate` function differs from cross_val_score in two ways -\n",
    "\n",
    "It allows specifying multiple metrics for evaluation.\n",
    "It returns a dict containing training scores, fit-times and score-times in addition to the test score.\n",
    "\n",
    "Here is [an example](http://scikit-learn.org/stable/modules/cross_validation.html#the-cross-validate-function-and-multiple-metric-evaluation) showing the usage of `corss_validate`.\n",
    "\n",
    "## Pipeline\n",
    "\n",
    "A pipeline of transforms with a final estimator. Sequentially apply a list of transforms and a final estimator. Intermediate steps of the pipeline must be ‘transforms’, that is, they must implement fit and transform methods. The final estimator only needs to implement fit.The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters. \n",
    "\n",
    "### Without Pipeline\n",
    "\n",
    "Just as it is important to test a predictor on data held-out from training, preprocessing (such as standardization, feature selection, etc.) and similar data transformations similarly should be learnt from a training set and applied to held-out data for prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93333333333333335"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=0)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_transformed = scaler.transform(X_train)\n",
    "clf = svm.SVC(C=1).fit(X_train_transformed, y_train)\n",
    "X_test_transformed = scaler.transform(X_test)\n",
    "clf.score(X_test_transformed, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.933333333333\n",
      "[ 1.          0.93333333  1.          1.          1.          0.93333333\n",
      "  0.93333333  1.          1.          1.        ]\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(preprocessing.StandardScaler(), svm.SVC(C=1))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(pipe.score(X_test, y_test))\n",
    "print(cross_val_score(clf, iris.data, iris.target, cv=10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the hyper parameters of an estimator\n",
    "\n",
    "Two generic approaches to sampling search candidates are provided in scikit-learn: for given values, `GridSearchCV` exhaustively considers all parameter combinations, while `RandomizedSearchCV` can sample a given number of candidates from a parameter space with a specified distribution.\n",
    "\n",
    "### Exhaustive Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Digits dataset\n",
    "digits = datasets.load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf', 'linear'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.05799494,  0.02742078,  0.05781357,  0.03631341,  0.06981454,\n",
       "         0.03142726,  0.03437529,  0.02812538,  0.06562598,  0.02812533,\n",
       "         0.03425915,  0.02656305,  0.06742547,  0.03079443,  0.03058553,\n",
       "         0.03021405]),\n",
       " 'mean_score_time': array([ 0.00665102,  0.00312481,  0.00625038,  0.00432508,  0.00748794,\n",
       "         0.0019624 ,  0.00468774,  0.00312514,  0.00781252,  0.0046875 ,\n",
       "         0.00395365,  0.00312498,  0.00432532,  0.        ,  0.00625041,\n",
       "         0.00196257]),\n",
       " 'mean_test_score': array([ 0.98329621,  0.97438753,  0.95879733,  0.97438753,  0.98329621,\n",
       "         0.97438753,  0.98106904,  0.97438753,  0.98329621,  0.97438753,\n",
       "         0.98218263,  0.97438753,  0.98329621,  0.97438753,  0.98218263,\n",
       "         0.97438753]),\n",
       " 'mean_train_score': array([ 0.99888658,  1.        ,  0.96881809,  1.        ,  1.        ,\n",
       "         1.        ,  0.99814385,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]),\n",
       " 'param_C': masked_array(data = [1 1 1 1 10 10 10 10 100 100 100 100 1000 1000 1000 1000],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_gamma': masked_array(data = [0.001 0.001 0.0001 0.0001 0.001 0.001 0.0001 0.0001 0.001 0.001 0.0001\n",
       "  0.0001 0.001 0.001 0.0001 0.0001],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_kernel': masked_array(data = ['rbf' 'linear' 'rbf' 'linear' 'rbf' 'linear' 'rbf' 'linear' 'rbf' 'linear'\n",
       "  'rbf' 'linear' 'rbf' 'linear' 'rbf' 'linear'],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'C': 1, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.0001, 'kernel': 'linear'}),\n",
       " 'rank_test_score': array([ 1,  8, 16,  8,  1,  8,  7,  8,  1,  8,  5,  8,  1,  8,  5,  8]),\n",
       " 'split0_test_score': array([ 0.98947368,  0.96842105,  0.98947368,  0.96842105,  0.98947368,\n",
       "         0.96842105,  0.98947368,  0.96842105,  0.98947368,  0.96842105,\n",
       "         1.        ,  0.96842105,  0.98947368,  0.96842105,  1.        ,\n",
       "         0.96842105]),\n",
       " 'split0_train_score': array([ 0.99875467,  1.        ,  0.96886675,  1.        ,  1.        ,\n",
       "         1.        ,  0.99875467,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]),\n",
       " 'split1_test_score': array([ 0.9893617 ,  0.9787234 ,  0.96808511,  0.9787234 ,  0.9893617 ,\n",
       "         0.9787234 ,  1.        ,  0.9787234 ,  0.9893617 ,  0.9787234 ,\n",
       "         1.        ,  0.9787234 ,  0.9893617 ,  0.9787234 ,  1.        ,\n",
       "         0.9787234 ]),\n",
       " 'split1_train_score': array([ 0.99875622,  1.        ,  0.96890547,  1.        ,  1.        ,\n",
       "         1.        ,  0.99875622,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]),\n",
       " 'split2_test_score': array([ 0.97802198,  0.97802198,  0.96703297,  0.97802198,  0.97802198,\n",
       "         0.97802198,  0.97802198,  0.97802198,  0.97802198,  0.97802198,\n",
       "         0.97802198,  0.97802198,  0.97802198,  0.97802198,  0.97802198,\n",
       "         0.97802198]),\n",
       " 'split2_train_score': array([ 1.        ,  1.        ,  0.96902107,  1.        ,  1.        ,\n",
       "         1.        ,  0.99876084,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]),\n",
       " 'split3_test_score': array([ 1.        ,  0.98901099,  0.96703297,  0.98901099,  1.        ,\n",
       "         0.98901099,  0.97802198,  0.98901099,  1.        ,  0.98901099,\n",
       "         0.98901099,  0.98901099,  1.        ,  0.98901099,  0.98901099,\n",
       "         0.98901099]),\n",
       " 'split3_train_score': array([ 0.99876084,  1.        ,  0.96530359,  1.        ,  1.        ,\n",
       "         1.        ,  0.99504337,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]),\n",
       " 'split4_test_score': array([ 0.97777778,  0.97777778,  0.97777778,  0.97777778,  0.97777778,\n",
       "         0.97777778,  0.97777778,  0.97777778,  0.97777778,  0.97777778,\n",
       "         0.97777778,  0.97777778,  0.97777778,  0.97777778,  0.97777778,\n",
       "         0.97777778]),\n",
       " 'split4_train_score': array([ 0.99876238,  1.        ,  0.96534653,  1.        ,  1.        ,\n",
       "         1.        ,  0.99752475,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]),\n",
       " 'split5_test_score': array([ 0.95454545,  0.94318182,  0.90909091,  0.94318182,  0.95454545,\n",
       "         0.94318182,  0.95454545,  0.94318182,  0.95454545,  0.94318182,\n",
       "         0.94318182,  0.94318182,  0.95454545,  0.94318182,  0.94318182,\n",
       "         0.94318182]),\n",
       " 'split5_train_score': array([ 0.99876543,  1.        ,  0.97160494,  1.        ,  1.        ,\n",
       "         1.        ,  0.99876543,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]),\n",
       " 'split6_test_score': array([ 0.96590909,  0.96590909,  0.94318182,  0.96590909,  0.96590909,\n",
       "         0.96590909,  0.94318182,  0.96590909,  0.96590909,  0.96590909,\n",
       "         0.96590909,  0.96590909,  0.96590909,  0.96590909,  0.96590909,\n",
       "         0.96590909]),\n",
       " 'split6_train_score': array([ 0.99876543,  1.        ,  0.97407407,  1.        ,  1.        ,\n",
       "         1.        ,  0.99876543,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]),\n",
       " 'split7_test_score': array([ 0.98863636,  0.95454545,  0.93181818,  0.95454545,  0.98863636,\n",
       "         0.95454545,  0.98863636,  0.95454545,  0.98863636,  0.95454545,\n",
       "         0.96590909,  0.95454545,  0.98863636,  0.95454545,  0.96590909,\n",
       "         0.95454545]),\n",
       " 'split7_train_score': array([ 0.99876543,  1.        ,  0.96790123,  1.        ,  1.        ,\n",
       "         1.        ,  0.99876543,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]),\n",
       " 'split8_test_score': array([ 1.        ,  0.98850575,  0.94252874,  0.98850575,  0.98850575,\n",
       "         0.98850575,  1.        ,  0.98850575,  0.98850575,  0.98850575,\n",
       "         1.        ,  0.98850575,  0.98850575,  0.98850575,  1.        ,\n",
       "         0.98850575]),\n",
       " 'split8_train_score': array([ 0.99876695,  1.        ,  0.97163995,  1.        ,  1.        ,\n",
       "         1.        ,  0.99753391,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]),\n",
       " 'split9_test_score': array([ 0.98837209,  1.        ,  0.98837209,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]),\n",
       " 'split9_train_score': array([ 0.99876847,  1.        ,  0.96551724,  1.        ,  1.        ,\n",
       "         1.        ,  0.99876847,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]),\n",
       " 'std_fit_time': array([ 0.00674568,  0.00625516,  0.00716098,  0.00967456,  0.01144343,\n",
       "         0.00621707,  0.00625027,  0.00625013,  0.00625011,  0.00624981,\n",
       "         0.00473009,  0.00716037,  0.0064687 ,  0.00228769,  0.00229624,\n",
       "         0.0040036 ]),\n",
       " 'std_score_time': array([ 0.00741945,  0.00624962,  0.00765512,  0.00590947,  0.00616294,\n",
       "         0.00470768,  0.00716064,  0.00625029,  0.00781252,  0.00716027,\n",
       "         0.00605256,  0.00624995,  0.00617465,  0.        ,  0.00765515,\n",
       "         0.00470799]),\n",
       " 'std_test_score': array([ 0.01359986,  0.01590859,  0.02460054,  0.01590859,  0.01359439,\n",
       "         0.01590859,  0.01822677,  0.01590859,  0.01359439,  0.01590859,\n",
       "         0.01836732,  0.01590859,  0.01359439,  0.01590859,  0.01836732,\n",
       "         0.01590859]),\n",
       " 'std_train_score': array([ 0.00037116,  0.        ,  0.00282038,  0.        ,  0.        ,\n",
       "         0.        ,  0.0011422 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,  0.        ])}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(svm.SVC(), tuned_parameters, cv=10, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(clf.best_params_)\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        89\n",
      "          1       0.97      1.00      0.98        90\n",
      "          2       0.99      0.98      0.98        92\n",
      "          3       1.00      0.99      0.99        93\n",
      "          4       0.99      1.00      0.99        76\n",
      "          5       0.99      0.97      0.98       108\n",
      "          6       0.99      1.00      0.99        89\n",
      "          7       0.99      1.00      0.99        78\n",
      "          8       1.00      0.98      0.99        92\n",
      "          9       0.99      0.99      0.99        92\n",
      "\n",
      "avg / total       0.99      0.99      0.99       899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
